{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.width = 2000\n",
    "pd.options.display.max_columns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price_to_float(data, data_dictionary):\n",
    "    \"\"\"\n",
    "    Function to convert string price columns into float price columns\n",
    "    :param data: type of data set\n",
    "    :param data_dictionary: dictionary with airbnb dataframes\n",
    "    :return: dictionary containing updated dataframes with float price columns\n",
    "    \"\"\"\n",
    "    string_columns = data_dictionary[data].select_dtypes(include=['object']).columns\n",
    "    price_columns = [col for col in string_columns if 'price' in col]\n",
    "    if len(price_columns) > 0:\n",
    "        for price in price_columns:\n",
    "            data_dictionary[data][price + '_float'] = data_dictionary[data][price]\\\n",
    "                .str\\\n",
    "                .replace('$', '')\\\n",
    "                .str\\\n",
    "                .replace(',', '')\\\n",
    "                .astype(float)\n",
    "    return data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(data, data_dictionary):\n",
    "    \"\"\"\n",
    "    Function to split date column into separate year, month, day columns\n",
    "    :param data: type of data set\n",
    "    :param data_dictionary: dictionary with airbnb dataframes\n",
    "    :return: dictionary containing updated dataframes with new date columns\n",
    "    \"\"\"\n",
    "    if 'date' in data_dictionary[data].select_dtypes(include=['object']).columns:\n",
    "        data_dictionary[data][['year','month','day']] = data_dictionary[data]['date']\\\n",
    "            .str.split('-', 3, expand=True)\n",
    "    return data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(cities, data_sets, source_directory):\n",
    "    \"\"\"\n",
    "    Function to load three types of csv data sets for Boston and Seattle\n",
    "    :param city_type: list of city names\n",
    "    :param data_type: list of data sets\n",
    "    :param source_directory: location of the csv data sets\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    city_dictionary = {}\n",
    "    for city in cities:\n",
    "        data_dictionary = {}\n",
    "        for data in data_sets:\n",
    "            file_path = source_directory + '/' + data + '-' + city + '.csv'\n",
    "            # 1. read csv into dataframe\n",
    "            data_dictionary[data] = pd.read_csv(file_path)\n",
    "            # 2. convert string price columns into float columns\n",
    "            data_dictionary = convert_price_to_float(data, data_dictionary)\n",
    "            # 3. split date column into separate year, month, day column\n",
    "            data_dictionary = split_date(data, data_dictionary)\n",
    "        city_dictionary[city] = data_dictionary\n",
    "    return city_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load files\n",
    "data_type = ['calendar'\n",
    "             , 'listings'\n",
    "             , 'reviews']\n",
    "\n",
    "city_type = ['seattle'\n",
    "             , 'boston']\n",
    "city_dictionary = load_csv(city_type, data_type, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['seattle', 'boston'])\n"
     ]
    }
   ],
   "source": [
    "print(city_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_dataframes(dictionary, data):\n",
    "    \"\"\"\n",
    "    Function to get combine datasets including data for each city\n",
    "    :param dictionary: complete data dictionary\n",
    "    :param data: particular data of interest\n",
    "    :return: dataframe including both cities\n",
    "    \"\"\"\n",
    "    seattle_df = dictionary['seattle'][data]\n",
    "    boston_df = dictionary['boston'][data]\n",
    "    seattle_df['boston'] = 0\n",
    "    boston_df['boston'] = 1\n",
    "    intersection_columns = set(seattle_df.columns).intersection(set(boston_df.columns))\n",
    "    df = pd.concat([seattle_df[intersection_columns], boston_df[intersection_columns]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = concatenate_dataframes(city_dictionary, 'reviews')\n",
    "listings_df = concatenate_dataframes(city_dictionary, 'listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    84849\n",
       "1    68275\n",
       "Name: boston, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['boston'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df, missing_values_maximum):\n",
    "    \"\"\"\n",
    "    Function to check what columns have the most amount of missing data\n",
    "    :param df: dataframe with data to compare\n",
    "    :param missing_values_maximum: value spevifying the cutoff for missing data\n",
    "    :return: list of columns that have more missing data than specified amount\n",
    "    \"\"\"\n",
    "    seattle_data = df[df['boston'] == 0].isnull().mean().reset_index()\n",
    "    boston_data = df[df['boston'] == 1].isnull().mean().reset_index()\n",
    "    boston_data.columns = ['index', 'boston']\n",
    "    seattle_data.columns = ['index', 'seattle']\n",
    "    merged_data = seattle_data.merge(boston_data, how='inner', on='index')\n",
    "    merged_data = merged_data.sort_values(by=['boston', 'seattle'], ascending=False)\n",
    "    print(merged_data.head(30))\n",
    "    missing_data_list = merged_data[(merged_data['boston'] > missing_values_maximum) \n",
    "                               | (merged_data['seattle'] > missing_values_maximum)]['index'].tolist()\n",
    "    return missing_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_specified_columns(key, df):\n",
    "    \"\"\"\n",
    "    Function to drop columns that include a specified substring\n",
    "    :param key: substring to specify columns to delete \n",
    "    :param df: dataframe to remove columns from\n",
    "    :return: updated dataframe\n",
    "    \"\"\"\n",
    "    drop_columns = [col for col in df.columns if key in col.lower()]\n",
    "    if len(drop_columns) > 0:\n",
    "        df = df.drop(columns=drop_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_float_columns(df):\n",
    "    columns_to_check = df\\\n",
    "            .select_dtypes(include=['bool', 'int64', 'float64'])\\\n",
    "            .columns\n",
    "    for column in columns_to_check:\n",
    "        if 'id' not in column:\n",
    "            print('\\n Describe ' + column)\n",
    "            seattle_data = df[df['boston'] == 0][column].describe().reset_index()\n",
    "            seattle_data.columns = ['index', column + '_seattle']\n",
    "            boston_data = df[df['boston'] == 1][column].describe().reset_index()\n",
    "            boston_data.columns = ['index', column + '-boston']\n",
    "            merged_data = seattle_data.merge(boston_data, how='inner', on='index')\n",
    "            print(merged_data.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
